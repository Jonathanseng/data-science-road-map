{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d844a734-a1ad-4dbf-b5f0-4a121b042f7d",
   "metadata": {},
   "source": [
    "# Machine Learning with Python - Feature Engineering\n",
    "The basics of feature engineering\n",
    "\n",
    "### sklearn\n",
    "Provides lots of tools to help!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd64b94-d5d7-4a4c-9816-400e304833fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267964fa-805b-4f2c-927d-eb0df18499db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in our titanic data\n",
    "df_og = pd.read_csv('data/train.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe925681-3ed4-4639-b802-de366fe89106",
   "metadata": {},
   "source": [
    "## one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90e70d-5f8e-4270-a6f7-0bbd52dbc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775944c-6f7a-490b-8f01-4908d164543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb = df_og['Embarked']\n",
    "df_emb.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2343e-c601-41fd-8a33-6d89b4b4837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb = df_emb.values.reshape(-1,1)\n",
    "# create an encoder and fit the dataframe\n",
    "enc = OneHotEncoder(sparse=False).fit(df_emb)\n",
    "encoded = enc.transform(df_emb)\n",
    "\n",
    "# convert it to a dataframe\n",
    "ohe_df = pd.DataFrame(\n",
    "     encoded, \n",
    "     columns=enc.get_feature_names_out()\n",
    ")\n",
    "print(ohe_df.head())\n",
    "print(ohe_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d81dd2-912c-4bcc-b56b-c35868fb0aae",
   "metadata": {},
   "source": [
    "## Text Embedding\n",
    "[OpenAI embedding service](https://beta.openai.com/docs/guides/embeddings/what-are-embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7407e2ec-7536-457d-a161-2d99c3cba074",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55bd61-b014-4323-93cc-7b5997ab739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og.Fare.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35936b-2fc0-4dcd-95f6-9ba2ceab4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og['logFare'] = np.log10(df_og['Fare'], where=df_og['Fare']>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f320205-f4f8-4f22-b242-7dbd720b8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og.logFare.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae3f4e-bc91-4f99-8c0a-8555123f0bac",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "Work derived, in part, from example in [this blog post.](https://towardsdatascience.com/image-compression-using-principal-component-analysis-pca-253f26740a9f) I have reduced the size of the data in order to include it in the GitHub repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6104865d-0773-4272-8a44-fbc9a445e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv('data/mnist.csv')\n",
    "mnist.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8554c-b7e1-48c0-8962-9e41a2b81cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc002cc-585b-4021-a875-f24388162150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mnist.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72262c4e-1897-45ac-84bf-255060f958b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_image = mnist.iloc[9].values.reshape([28,28])\n",
    "plt.imshow(second_image, cmap='gray_r')\n",
    "plt.title('Tenth image: Digit 4', fontsize=15, pad=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521cd1fc-e38a-4573-94b6-abd791f7747c",
   "metadata": {},
   "source": [
    "Next step would be is to scale the features so they are on the same or similar ranges. PCA is very senstive so scale as the method is based on explained variance. Larger sacled values would produce much greater variance. However, in an image all values are already scaled at each pixel (0 to 255 in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30165a89-549a-4fc4-a232-f0acd609cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist.iloc[1].min())\n",
    "print(mnist.iloc[1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a0ad6-7361-445d-a7f5-79b8d3e7dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_784 = PCA(n_components=784)\n",
    "pca_784.fit(mnist)\n",
    "\n",
    "plt.grid()\n",
    "plt.plot(np.cumsum(pca_784.explained_variance_ratio_ * 100))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519eb8e6-0568-4e34-9e5b-03be459e4645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's just use the first 25 components\n",
    "pca_25 = PCA(n_components=25)\n",
    "mnist_pca_25_reduced = pca_25.fit_transform(mnist)\n",
    "mnist_pca_25_recovered = pca_25.inverse_transform(mnist_pca_25_reduced)\n",
    "\n",
    "image_pca_25 = mnist_pca_25_recovered[1,:].reshape([28,28])\n",
    "plt.imshow(image_pca_25, cmap='gray_r')\n",
    "plt.title('Compressed image with 25 components', fontsize=15, pad=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673a3bf-bc01-4328-83c0-ccf33335aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's expand to 200 components\n",
    "pca_200 = PCA(n_components=200)\n",
    "mnist_pca_200_reduced = pca_200.fit_transform(mnist)\n",
    "mnist_pca_200_recovered = pca_200.inverse_transform(mnist_pca_200_reduced)\n",
    "\n",
    "image_pca_200 = mnist_pca_200_recovered[1,:].reshape([28,28])\n",
    "plt.imshow(image_pca_200, cmap='gray_r')\n",
    "plt.title('Compressed image with 200 components', fontsize=15, pad=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f27d2-a2e5-4078-a1f3-cc6ce04d79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explained variance\n",
    "print(np.cumsum(pca_25.explained_variance_ratio_ * 100)[-1])\n",
    "print(np.cumsum(pca_200.explained_variance_ratio_ * 100)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb7159-366b-43be-98f4-8d50719c1918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
